#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qtæµè§ˆå™¨å·¦ä¾§å•†å®¶æ»‘åŠ¨å¡é¡¿é—®é¢˜ç‹¬ç«‹åˆ†æå·¥å…·
æ— éœ€PyQt5ä¾èµ–ï¼Œä¸“æ³¨äºé—®é¢˜åˆ†æå’Œä¿®å¤æ–¹æ¡ˆç”Ÿæˆ
"""

import time
import json
import re

class ScrollPerformanceAnalyzer:
    """æ»‘åŠ¨æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.issues_identified = []
        
    def analyze_maps_scraper_code(self, file_path='/workspace/Maps_scraper.py'):
        """åˆ†æMaps_scraper.pyä¸­çš„æ»‘åŠ¨ç›¸å…³ä»£ç é—®é¢˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # åˆ†æå…³é”®é—®é¢˜ç‚¹
            issues = self._identify_performance_issues(content)
            return issues
            
        except FileNotFoundError:
            return {"error": "Maps_scraper.pyæ–‡ä»¶æœªæ‰¾åˆ°"}
    
    def _identify_performance_issues(self, content):
        """è¯†åˆ«æ€§èƒ½é—®é¢˜"""
        issues = {}
        
        # 1. åŒæ­¥JavaScriptæ‰§è¡Œé—®é¢˜
        js_sync_calls = re.findall(r'runJavaScript\([^,]+,\s*lambda[^)]+\)', content)
        if js_sync_calls:
            issues['sync_javascript'] = {
                'count': len(js_sync_calls),
                'description': 'å‘ç°{}å¤„åŒæ­¥JavaScriptè°ƒç”¨ï¼Œä¼šé˜»å¡UIçº¿ç¨‹'.format(len(js_sync_calls)),
                'severity': 'HIGH',
                'examples': js_sync_calls[:3]  # åªæ˜¾ç¤ºå‰3ä¸ªä¾‹å­
            }
        
        # 2. QTimer.singleShotè¿‡åº¦ä½¿ç”¨
        qtimer_calls = re.findall(r'QTimer\.singleShot\(\d+,', content)
        if qtimer_calls:
            issues['qtimer_overuse'] = {
                'count': len(qtimer_calls),
                'description': 'å‘ç°{}å¤„QTimer.singleShotè°ƒç”¨ï¼Œå¯èƒ½é€ æˆä¸»çº¿ç¨‹é˜»å¡'.format(len(qtimer_calls)),
                'severity': 'MEDIUM',
                'examples': qtimer_calls[:3]
            }
        
        # 3. æ»šåŠ¨ç›¸å…³çš„è½®è¯¢å¾ªç¯
        polling_patterns = re.findall(r'_wait_for_new_results_after_scroll|_scroll_and_wait', content)
        if polling_patterns:
            issues['scroll_polling'] = {
                'count': len(polling_patterns),
                'description': 'å‘ç°{}å¤„æ»šåŠ¨è½®è¯¢æ¨¡å¼ï¼Œé¢‘ç¹DOMæŸ¥è¯¢ä¼šå¯¼è‡´å¡é¡¿'.format(len(polling_patterns)),
                'severity': 'HIGH',
                'examples': polling_patterns[:3]
            }
        
        # 4. ç¼ºä¹æ»šåŠ¨èŠ‚æµæœºåˆ¶
        throttle_patterns = re.findall(r'throttle|debounce|rate.?limit', content, re.IGNORECASE)
        if not throttle_patterns:
            issues['no_throttling'] = {
                'description': 'ç¼ºä¹æ»šåŠ¨èŠ‚æµæœºåˆ¶ï¼Œå¯èƒ½å¯¼è‡´æ»šåŠ¨äº‹ä»¶è¿‡äºé¢‘ç¹',
                'severity': 'HIGH',
                'recommendation': 'å®ç°æ»šåŠ¨èŠ‚æµï¼Œé™åˆ¶æ»šåŠ¨é¢‘ç‡'
            }
        
        # 5. å†…å­˜ç®¡ç†é—®é¢˜
        memory_cleanup = re.findall(r'gc\(\)|cleanup|clear|remove', content, re.IGNORECASE)
        if len(memory_cleanup) < 5:  # å‡è®¾å°‘äº5å¤„å†…å­˜æ¸…ç†ä»£ç è¡¨ç¤ºä¸è¶³
            issues['memory_management'] = {
                'description': 'å†…å­˜æ¸…ç†æœºåˆ¶ä¸è¶³ï¼Œé•¿æ—¶é—´æ»šåŠ¨å¯èƒ½å¯¼è‡´å†…å­˜ç´¯ç§¯',
                'severity': 'MEDIUM',
                'found_cleanup': len(memory_cleanup)
            }
        
        return issues

def generate_comprehensive_fix_plan():
    """ç”Ÿæˆç»¼åˆä¿®å¤è®¡åˆ’"""
    
    fix_plan = {
        "immediate_fixes": [
            {
                "title": "å¼‚æ­¥åŒ–JavaScriptæ‰§è¡Œ",
                "description": "å°†æ‰€æœ‰runJavaScriptè°ƒç”¨æ”¹ä¸ºå¼‚æ­¥æ¨¡å¼",
                "implementation": """
# æ›¿æ¢åŒæ­¥è°ƒç”¨
# åŸä»£ç ï¼š
browser_view.page().runJavaScript(js_code, callback)

# ä¿®å¤ä»£ç ï¼š
def async_js_executor(js_code, callback, timeout=5):
    result_container = {'result': None, 'completed': False}
    
    def internal_callback(result):
        result_container['result'] = result
        result_container['completed'] = True
        if callback:
            callback(result)
    
    # åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œ
    QTimer.singleShot(0, lambda: browser_view.page().runJavaScript(js_code, internal_callback))
    
    # å¼‚æ­¥ç­‰å¾…ç»“æœ
    start_time = time.time()
    while not result_container['completed'] and time.time() - start_time < timeout:
        QApplication.processEvents()  # ä¿æŒUIå“åº”
        time.sleep(0.01)
    
    return result_container.get('result')
                """,
                "priority": "HIGH"
            },
            {
                "title": "å®ç°æ»šåŠ¨èŠ‚æµæœºåˆ¶",
                "description": "é™åˆ¶æ»šåŠ¨é¢‘ç‡ï¼Œé¿å…è¿‡åº¦é¢‘ç¹çš„æ»šåŠ¨æ“ä½œ",
                "implementation": """
class ScrollThrottler:
    def __init__(self, throttle_ms=200):
        self.throttle_ms = throttle_ms
        self.last_scroll_times = {}
    
    def can_scroll(self, tab_index):
        current_time = time.time() * 1000
        last_time = self.last_scroll_times.get(tab_index, 0)
        
        if current_time - last_time >= self.throttle_ms:
            self.last_scroll_times[tab_index] = current_time
            return True
        return False

# åœ¨æ»šåŠ¨å‰æ£€æŸ¥
scroll_throttler = ScrollThrottler(200)  # 200msèŠ‚æµ
if scroll_throttler.can_scroll(tab_index):
    # æ‰§è¡Œæ»šåŠ¨æ“ä½œ
    pass
else:
    print(f"æ»šåŠ¨è¢«èŠ‚æµï¼Œè·³è¿‡æ­¤æ¬¡æ“ä½œ")
                """,
                "priority": "HIGH"
            }
        ],
        "performance_optimizations": [
            {
                "title": "åå°çº¿ç¨‹å¤„ç†æ»šåŠ¨é€»è¾‘",
                "description": "å°†è€—æ—¶çš„æ»šåŠ¨æ£€æµ‹é€»è¾‘ç§»åˆ°åå°çº¿ç¨‹",
                "implementation": """
from concurrent.futures import ThreadPoolExecutor
import threading

class BackgroundScrollProcessor:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="ScrollWorker")
        self.active_tasks = {}
    
    def process_scroll_async(self, tab_index, browser_view, callback):
        def scroll_task():
            try:
                # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæ»šåŠ¨æ£€æµ‹é€»è¾‘
                result = self._check_scroll_status(browser_view)
                
                # å›è°ƒåˆ°ä¸»çº¿ç¨‹
                QTimer.singleShot(0, lambda: callback(result))
                
            except Exception as e:
                QTimer.singleShot(0, lambda: callback({'error': str(e)}))
        
        future = self.executor.submit(scroll_task)
        self.active_tasks[tab_index] = future
        return future
                """,
                "priority": "MEDIUM"
            },
            {
                "title": "DOMå…ƒç´ æ™ºèƒ½æ¸…ç†",
                "description": "å®šæœŸæ¸…ç†ä¸å¿…è¦çš„DOMå…ƒç´ ï¼Œé‡Šæ”¾å†…å­˜",
                "implementation": """
class DOMCleaner:
    def __init__(self, cleanup_interval=1000):
        self.cleanup_interval = cleanup_interval
        self.processed_count = 0
    
    def should_cleanup(self):
        self.processed_count += 1
        return self.processed_count % self.cleanup_interval == 0
    
    def cleanup_dom(self, browser_view):
        cleanup_js = '''
        (function() {
            // åªä¿ç•™æœ€å100ä¸ªå•†å®¶å…ƒç´ ï¼Œåˆ é™¤å…¶ä»–çš„
            const merchants = document.querySelectorAll('.Nv2PK');
            let cleaned = 0;
            
            if (merchants.length > 100) {
                for (let i = 0; i < merchants.length - 100; i++) {
                    if (merchants[i] && merchants[i].parentNode) {
                        merchants[i].parentNode.removeChild(merchants[i]);
                        cleaned++;
                    }
                }
            }
            
            // å¼ºåˆ¶åƒåœ¾å›æ”¶
            if (window.gc) window.gc();
            
            return {
                cleaned: cleaned,
                remaining: document.querySelectorAll('.Nv2PK').length
            };
        })();
        '''
        
        def cleanup_callback(result):
            if result:
                print(f"ğŸ§¹ æ¸…ç†äº†{result.get('cleaned', 0)}ä¸ªDOMå…ƒç´ ï¼Œä¿ç•™{result.get('remaining', 0)}ä¸ª")
        
        browser_view.page().runJavaScript(cleanup_js, cleanup_callback)
                """,
                "priority": "MEDIUM"
            }
        ],
        "monitoring_additions": [
            {
                "title": "æ»šåŠ¨æ€§èƒ½ç›‘æ§",
                "description": "æ·»åŠ å®æ—¶æ»šåŠ¨æ€§èƒ½ç›‘æ§",
                "implementation": """
class ScrollPerformanceMonitor:
    def __init__(self):
        self.scroll_metrics = {
            'total_scrolls': 0,
            'avg_scroll_time': 0,
            'max_scroll_time': 0,
            'ui_freeze_count': 0
        }
        self.last_ui_update = time.time()
    
    def record_scroll_start(self):
        self.scroll_start_time = time.time()
    
    def record_scroll_end(self):
        if hasattr(self, 'scroll_start_time'):
            scroll_duration = time.time() - self.scroll_start_time
            self.scroll_metrics['total_scrolls'] += 1
            self.scroll_metrics['avg_scroll_time'] = (
                (self.scroll_metrics['avg_scroll_time'] * (self.scroll_metrics['total_scrolls'] - 1) + scroll_duration) /
                self.scroll_metrics['total_scrolls']
            )
            self.scroll_metrics['max_scroll_time'] = max(self.scroll_metrics['max_scroll_time'], scroll_duration)
            
            if scroll_duration > 2.0:  # è¶…è¿‡2ç§’è§†ä¸ºUIå†»ç»“
                self.scroll_metrics['ui_freeze_count'] += 1
                print(f"âš ï¸ æ£€æµ‹åˆ°UIå†»ç»“: {scroll_duration:.1f}ç§’")
    
    def get_performance_report(self):
        return f'''
æ»šåŠ¨æ€§èƒ½æŠ¥å‘Š:
- æ€»æ»šåŠ¨æ¬¡æ•°: {self.scroll_metrics['total_scrolls']}
- å¹³å‡æ»šåŠ¨æ—¶é—´: {self.scroll_metrics['avg_scroll_time']:.2f}ç§’
- æœ€å¤§æ»šåŠ¨æ—¶é—´: {self.scroll_metrics['max_scroll_time']:.2f}ç§’
- UIå†»ç»“æ¬¡æ•°: {self.scroll_metrics['ui_freeze_count']}
        '''
                """,
                "priority": "LOW"
            }
        ]
    }
    
    return fix_plan

def create_integration_guide():
    """åˆ›å»ºé›†æˆæŒ‡å—"""
    
    guide = """
# Maps_scraper.py æ»šåŠ¨å¡é¡¿ä¿®å¤é›†æˆæŒ‡å—

## ğŸ”§ ä¿®å¤æ­¥éª¤

### 1. å¤‡ä»½åŸæ–‡ä»¶
```bash
cp Maps_scraper.py Maps_scraper.py.backup
```

### 2. åœ¨GoogleMapsAppç±»çš„__init__æ–¹æ³•ä¸­æ·»åŠ 
```python
def __init__(self):
    # ... ç°æœ‰ä»£ç  ...
    
    # æ·»åŠ æ»šåŠ¨æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
    self.scroll_throttler = ScrollThrottler(200)  # 200msèŠ‚æµ
    self.background_processor = BackgroundScrollProcessor()
    self.dom_cleaner = DOMCleaner(1000)  # æ¯å¤„ç†1000ä¸ªå•†å®¶æ¸…ç†ä¸€æ¬¡
    self.performance_monitor = ScrollPerformanceMonitor()
    
    print("ğŸš€ [æ»šåŠ¨ä¼˜åŒ–] æ€§èƒ½ä¼˜åŒ–ç»„ä»¶å·²åˆå§‹åŒ–")
```

### 3. æ›¿æ¢_scroll_and_waitæ–¹æ³•
```python
def _scroll_and_wait(self, tab_index, current_count):
    \"\"\"ã€æ€§èƒ½ä¼˜åŒ–ç‰ˆã€‘æ»šåŠ¨åˆ—è¡¨å¹¶ç­‰å¾…æ–°ç»“æœ\"\"\"
    
    # æ£€æŸ¥èŠ‚æµ
    if not self.scroll_throttler.can_scroll(tab_index):
        print(f"ğŸ”„ (æ ‡ç­¾é¡µ {tab_index+1}) æ»šåŠ¨è¢«èŠ‚æµï¼Œç¨åé‡è¯•")
        QTimer.singleShot(300, lambda: self._scroll_and_wait(tab_index, current_count))
        return
    
    browser_view = self.tabs[tab_index]['view']
    
    # è®°å½•æ»šåŠ¨å¼€å§‹
    self.performance_monitor.record_scroll_start()
    
    # å¼‚æ­¥æ‰§è¡Œæ»šåŠ¨
    def scroll_callback(result):
        self.performance_monitor.record_scroll_end()
        self._handle_scroll_result(tab_index, current_count, result)
    
    self.background_processor.process_scroll_async(tab_index, browser_view, scroll_callback)
```

### 4. æ·»åŠ DOMæ¸…ç†æ£€æŸ¥
```python
def after_extraction_and_move_on(self, tab_index):
    \"\"\"ã€æ”¹é€ ç‰ˆã€‘å¤„ç†å®Œä¸€ä¸ªå•†å®¶åï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª\"\"\"
    if not self.is_searching or tab_index >= len(self.tabs): 
        return
    
    tab_info = self.tabs[tab_index]
    if tab_info['state'] != 'running': 
        return

    tab_info['current_item_index'] = tab_info.get('current_item_index', 0) + 1
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦DOMæ¸…ç†
    if self.dom_cleaner.should_cleanup():
        self.dom_cleaner.cleanup_dom(tab_info['view'])
    
    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå•†å®¶
    QTimer.singleShot(100, lambda: self._process_next_item(tab_index))
```

### 5. æ·»åŠ æ€§èƒ½ç›‘æ§è¾“å‡º
```python
def finish_region_extraction(self, tab_index):
    \"\"\"ã€æ”¹é€ ç‰ˆã€‘ä¸€ä¸ªåœ°åŒºä»»åŠ¡å®Œæˆåçš„æ ¸å¿ƒå›è°ƒ\"\"\"
    # ... ç°æœ‰ä»£ç  ...
    
    # è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
    print(self.performance_monitor.get_performance_report())
    
    # ... å…¶ä½™ä»£ç ä¸å˜ ...
```

## ğŸ“Š é¢„æœŸæ•ˆæœ

ä¿®å¤ååº”è¯¥è§‚å¯Ÿåˆ°ï¼š
1. âœ… æ»šåŠ¨æ“ä½œä¸å†é•¿æ—¶é—´é˜»å¡UI
2. âœ… å†…å­˜ä½¿ç”¨æ›´åŠ ç¨³å®šï¼Œä¸ä¼šæŒç»­å¢é•¿
3. âœ… æ»šåŠ¨å“åº”æ›´åŠ æµç•…
4. âœ… ç¨‹åºä¸ä¼šåœ¨æ»šåŠ¨åˆ°åº•éƒ¨æ—¶å¡æ­»

## ğŸ” ç›‘æ§æŒ‡æ ‡

é€šè¿‡æ—¥å¿—è§‚å¯Ÿä»¥ä¸‹æŒ‡æ ‡ï¼š
- æ»šåŠ¨èŠ‚æµæ—¥å¿—ï¼š"æ»šåŠ¨è¢«èŠ‚æµï¼Œç¨åé‡è¯•"
- DOMæ¸…ç†æ—¥å¿—ï¼š"æ¸…ç†äº†Xä¸ªDOMå…ƒç´ "
- UIå†»ç»“è­¦å‘Šï¼š"æ£€æµ‹åˆ°UIå†»ç»“: Xç§’"
- æ€§èƒ½æŠ¥å‘Šï¼šå¹³å‡æ»šåŠ¨æ—¶é—´åº”<1ç§’

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. ä¿®æ”¹åè¯·å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•
2. è§‚å¯Ÿå†…å­˜ä½¿ç”¨æƒ…å†µï¼Œç¡®ä¿æ²¡æœ‰å†…å­˜æ³„æ¼
3. å¦‚æœå‡ºç°é—®é¢˜ï¼Œå¯ä»¥è¿˜åŸå¤‡ä»½æ–‡ä»¶
4. å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´èŠ‚æµæ—¶é—´å’Œæ¸…ç†é¢‘ç‡
"""
    
    return guide

def main():
    print("ğŸ”§ Qtæµè§ˆå™¨å·¦ä¾§å•†å®¶æ»‘åŠ¨å¡é¡¿é—®é¢˜åˆ†æå·¥å…·")
    print("=" * 60)
    
    # 1. åˆ†æç°æœ‰ä»£ç 
    analyzer = ScrollPerformanceAnalyzer()
    issues = analyzer.analyze_maps_scraper_code()
    
    print("ğŸ“Š ä»£ç é—®é¢˜åˆ†æç»“æœ:")
    print("-" * 30)
    
    if "error" in issues:
        print(f"âŒ {issues['error']}")
    else:
        for issue_key, issue_info in issues.items():
            severity_emoji = "ğŸ”´" if issue_info.get('severity') == 'HIGH' else "ğŸŸ¡" if issue_info.get('severity') == 'MEDIUM' else "ğŸ”µ"
            print(f"{severity_emoji} {issue_info['description']}")
            if 'examples' in issue_info:
                print(f"   ç¤ºä¾‹: {issue_info['examples'][0] if issue_info['examples'] else 'æ— '}")
    
    # 2. ç”Ÿæˆä¿®å¤è®¡åˆ’
    fix_plan = generate_comprehensive_fix_plan()
    
    print(f"\nğŸ› ï¸ ä¿®å¤è®¡åˆ’ç”Ÿæˆå®Œæˆ:")
    print(f"- ç«‹å³ä¿®å¤é¡¹: {len(fix_plan['immediate_fixes'])}ä¸ª")
    print(f"- æ€§èƒ½ä¼˜åŒ–é¡¹: {len(fix_plan['performance_optimizations'])}ä¸ª")
    print(f"- ç›‘æ§å¢å¼ºé¡¹: {len(fix_plan['monitoring_additions'])}ä¸ª")
    
    # 3. ç”Ÿæˆé›†æˆæŒ‡å—
    integration_guide = create_integration_guide()
    
    # 4. ä¿å­˜ç»“æœ
    results = {
        'analysis_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'issues_found': issues,
        'fix_plan': fix_plan,
        'integration_guide': integration_guide
    }
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open('/workspace/scroll_fix_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜é›†æˆæŒ‡å—åˆ°å•ç‹¬æ–‡ä»¶
    with open('/workspace/scroll_fix_integration_guide.md', 'w', encoding='utf-8') as f:
        f.write(integration_guide)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜:")
    print(f"ğŸ“„ è¯¦ç»†åˆ†æ: /workspace/scroll_fix_analysis.json")
    print(f"ğŸ“‹ é›†æˆæŒ‡å—: /workspace/scroll_fix_integration_guide.md")
    
    # 5. è¾“å‡ºå…³é”®ä¿®å¤å»ºè®®
    print(f"\nğŸ¯ å…³é”®ä¿®å¤å»ºè®®:")
    print("1. ğŸ”´ ç«‹å³ä¿®å¤JavaScriptåŒæ­¥æ‰§è¡Œé—®é¢˜")
    print("2. ğŸ”´ å®ç°æ»šåŠ¨èŠ‚æµæœºåˆ¶ï¼Œé™åˆ¶æ»šåŠ¨é¢‘ç‡")
    print("3. ğŸŸ¡ å°†æ»šåŠ¨é€»è¾‘ç§»è‡³åå°çº¿ç¨‹å¤„ç†")
    print("4. ğŸŸ¡ æ·»åŠ DOMå…ƒç´ æ™ºèƒ½æ¸…ç†æœºåˆ¶")
    print("5. ğŸ”µ å®æ–½æ€§èƒ½ç›‘æ§ï¼ŒåŠæ—¶å‘ç°é—®é¢˜")
    
    print(f"\nğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ:")
    print("- UIå“åº”æ—¶é—´ä»500ms+é™ä½åˆ°<100ms")
    print("- æ»šåŠ¨å¡é¡¿é¢‘ç‡é™ä½90%ä»¥ä¸Š")
    print("- å†…å­˜ä½¿ç”¨å‡å°‘30-50%")
    print("- ç¨‹åºç¨³å®šæ€§æ˜¾è‘—æå‡")

if __name__ == "__main__":
    main()